# @livingdata/pipex-core

Programmatic TypeScript API for the Pipex containerized pipeline engine.

Use this package to embed pipeline execution in your own tools, build custom orchestrators, or interact with workspaces and runs programmatically.

## Installation

```bash
npm install @livingdata/pipex-core
```

## Usage

```typescript
import {Pipex} from '@livingdata/pipex-core'

// Zero config — Docker runtime, console reporter, built-in kits (shell, node, python)
const pipex = new Pipex()

// Load from file or JS object
const pipeline = await pipex.load('./pipeline.yaml')
const pipeline = await pipex.load({
  id: 'my-pipeline',
  steps: [{id: 'greet', uses: 'shell', with: {run: 'echo hello'}}]
})

// Run the pipeline (all steps, or targeted)
await pipex.run(pipeline)
await pipex.run(pipeline, {target: ['greet']})

// Execute a single step in a workspace
const step = await pipex.loadStep('./step.yaml')
await pipex.exec('my-workspace', step, {inputs: ['download']})

// Workspace operations
const workspaces = await pipex.workspaces()             // list all
await pipex.removeWorkspace('old-build')                // remove
await pipex.clean()                                     // remove all

const ws = await pipex.workspace('my-workspace')        // open existing
const info = await ws.show()                            // list steps
const logs = await ws.logs('download')                  // read logs
const meta = await ws.inspect('download')               // read metadata
const entries = await ws.listArtifacts('download')      // list artifacts
const buf = await ws.readArtifact('download', 'out.csv')// read artifact
await ws.exportArtifacts('download', './output')        // export to host
await ws.prune()                                        // remove old runs
await ws.removeStep('download')                         // remove step
await ws.remove()                                       // remove workspace
```

All options are optional:

```typescript
const pipex = new Pipex({
  workdir: './workdir',      // default: './workdir'
  kits: [{                   // custom kits (added to built-ins)
    name: 'rust',
    resolve: (params) => ({image: `rust:${params.version ?? '1'}`, cmd: ['cargo', 'run']})
  }]
})
```

## Custom Kits

Beyond the built-in kits (`shell`, `node`, `python`), you can register custom kits.

### Via `.pipex.yml` (CLI)

```yaml
kits:
  geo: ./kits/geo.js           # local file
  ml: @myorg/pipex-kit-ml      # npm package
```

### Via `Pipex` options (programmatic)

```typescript
const pipex = new Pipex({
  kits: [{
    name: 'rust',
    resolve: (params) => ({
      image: `rust:${params.version ?? '1'}`,
      cmd: ['cargo', 'run'],
      sources: [{host: params.src ?? '.', container: '/app'}]
    })
  }]
})
```

### As a JS module

A kit is a JS module exporting a default function that returns `{image, cmd}` (plus optional `setup`, `env`, `caches`, `mounts`, `sources`):

```javascript
// kits/rust.js
export default function (params) {
  return {
    image: `rust:${params.version ?? '1'}`,
    cmd: ['cargo', 'run'],
    sources: [{host: params.src ?? '.', container: '/app'}]
  }
}
```

### Kit resolution order

When a step uses `uses: <name>`, the kit is resolved in this order:

1. **`.pipex.yml` aliases** — mapped name → file path or npm specifier
2. **`kits/<name>/index.js`** — local directory
3. **`kits/<name>.js`** — local file
4. **Custom kits** — kits passed via `new Pipex({kits: [...]})`
5. **Built-in** — `shell`, `node`, `python`
6. **npm module** — for scoped packages (`@org/kit-name`)

## Main Exports

### Pipex Facade

- **`Pipex`** — Main entry point. Configure once, load/run pipelines, exec single steps, manage workspaces. Built-in kits always available.
- **`PipexWorkspace`** — Workspace handle returned by `pipex.workspace()`. Provides show, logs, inspect, artifact read/export, prune, remove operations.

### Engine

- **`Workspace`** — Manages isolated execution environments (staging → commit lifecycle, artifact storage, caches)
- **`DockerCliExecutor`** — Runs containers via Docker CLI with mount configuration, log streaming, and two-phase execution
- **`ContainerExecutor`** — Abstract base class for pluggable container runtimes

### Orchestration

- **`PipelineRunner`** — DAG-based parallel step execution with fingerprint caching. Takes a `Pipeline` object.
- **`StepRunner`** — Single-step executor for interactive/exploratory workflows
- **`PipelineLoader`** — Constructor takes optional `KitContext`. Loads from file paths or JS objects (`PipelineDefinition`). Also provides `loadStep()`.
- **`StateManager`** — Persists step fingerprints and run IDs for cache hit detection
- **`CacheLockManager`** — In-memory async mutex for exclusive cache access during setup phases

### Built-in Kits

- **`defaultKits`** — Map of all built-in kits (shell, node, python)
- **`shellKit`**, **`nodeKit`**, **`pythonKit`** — Individual kit objects

### Kit Registry

- **`resolveKit(name, context?)`** — Resolves a kit by name: alias → local dir → local file → custom kits → built-in defaults → npm module
- **`loadExternalKit(specifier, cwd)`** — Loads a kit from a file path or npm specifier

### DAG Utilities

- **`buildGraph`**, **`validateGraph`**, **`topologicalLevels`**, **`subgraph`**, **`leafNodes`**

### Reporting

- **`ConsoleReporter`** — Structured JSON output via Pino
- **`StreamReporter`**, **`CompositeReporter`** — Composable event-based reporters
- **`EventAggregator`** — Aggregates pipeline events into session state

### Types

All domain types are exported: `Pipeline`, `Step`, `Kit`, `KitContext`, `KitOutput`, `StepDefinition`, `PipelineDefinition`, `PipexConfig`, etc.

### Errors

Structured error hierarchy: `PipexError` → `DockerError`, `WorkspaceError`, `PipelineError`, `KitError` with specific subclasses.
